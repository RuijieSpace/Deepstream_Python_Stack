# Custom Model Video Detection Guide

## 02_custom_model - è‡ªå®šä¹‰æ¨¡å‹è§†é¢‘æ£€æµ‹

[English](#english-version) | [ä¸­æ–‡](#ä¸­æ–‡ç‰ˆæœ¬)

---

## ä¸­æ–‡ç‰ˆæœ¬

### ğŸ“– æ¦‚è¿°

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•åœ¨ DeepStream ä¸­ä½¿ç”¨è‡ªå®šä¹‰ YOLOv8 æ¨¡å‹è¿›è¡Œè§†é¢‘ç›®æ ‡æ£€æµ‹ã€‚åŒ…å«å®Œæ•´çš„æ¨¡å‹è½¬æ¢ã€é…ç½®å’Œæ¨ç†æµç¨‹ã€‚

### âœ¨ åŠŸèƒ½ç‰¹ç‚¹

- âœ… æ”¯æŒ YOLOv8 ç³»åˆ—æ¨¡å‹ï¼ˆn/s/m/l/xï¼‰
- âœ… è‡ªå®šä¹‰è¾“å…¥å°ºå¯¸ï¼ˆé»˜è®¤ 640Ã—640ï¼Œå¯è°ƒæ•´ï¼‰
- âœ… åŠ¨æ€ batch size æ”¯æŒ
- âœ… ONNX æ¨¡å‹è½¬æ¢å’Œä¼˜åŒ–
- âœ… TensorRT åŠ é€Ÿæ¨ç†
- âœ… æ€§èƒ½ç›‘æ§å’Œ FPS ç»Ÿè®¡

### ğŸ“‹ å‰ç½®æ¡ä»¶

ç¡®ä¿ä½ å·²ç»å®Œæˆäº†åŸºç¡€ç¯å¢ƒé…ç½®ï¼š

```bash
# 1. DeepStream 8.0 ç¯å¢ƒå·²å®‰è£…
deepstream-app --version

# 2. Python Bindings (pyds) å·²å®‰è£…
python3 -c "import pyds; print(pyds.__version__)"

# 3. DeepStream-Yolo å·²ç¼–è¯‘
ls /opt/nvidia/deepstream/deepstream/my_apps/DeepStream-Yolo/nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
```

å¦‚æœæœªå®Œæˆï¼Œè¯·å‚è€ƒä¸» README çš„[å®Œæ•´éƒ¨ç½²æµç¨‹](../../README.md#å®Œæ•´éƒ¨ç½²æµç¨‹)ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ­¥éª¤ 1ï¼šå®‰è£… DeepStream-Yolo

å¦‚æœè¿˜æ²¡æœ‰å®‰è£… DeepStream-Yoloï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# è¿›å…¥å·¥ä½œç›®å½•
cd /opt/nvidia/deepstream/deepstream/my_apps

# å…‹éš† DeepStream-Yolo ä»“åº“
git clone https://github.com/marcoslucianops/DeepStream-Yolo.git
cd DeepStream-Yolo

# è®¾ç½® CUDA ç‰ˆæœ¬ï¼ˆæ ¹æ® DeepStream ç‰ˆæœ¬é€‰æ‹©ï¼‰
export CUDA_VER=12.8  # DeepStream 8.0

# ç¼–è¯‘è‡ªå®šä¹‰åº“
make -C nvdsinfer_custom_impl_Yolo clean && \
make -C nvdsinfer_custom_impl_Yolo

# éªŒè¯ç¼–è¯‘
ls -lh nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
```

**CUDA ç‰ˆæœ¬å¯¹ç…§è¡¨**ï¼š

| DeepStream ç‰ˆæœ¬ | CUDA ç‰ˆæœ¬ |
|----------------|-----------|
| 8.0 | 12.8 |
| 7.1 | 12.6 |
| 7.0 / 6.4 | 12.2 |
| 6.3 | 12.1 |
| 6.2 | 11.8 |
| 6.1.1 | 11.7 |
| 6.1 | 11.6 |
| 6.0.1 / 6.0 | 11.4 |
| 5.1 | 11.1 |

---

### æ­¥éª¤ 2ï¼šå‡†å¤‡ YOLOv8 ç¯å¢ƒ

```bash
# å…‹éš† ultralytics ä»“åº“
cd /opt/nvidia/deepstream/deepstream/my_apps
git clone https://github.com/ultralytics/ultralytics.git
cd ultralytics

# å®‰è£…ä¾èµ–
pip3 install -e .
pip3 install onnx onnxslim onnxruntime tensorrt
```

---

### æ­¥éª¤ 3ï¼šå¤åˆ¶æ¨¡å‹è½¬æ¢è„šæœ¬

```bash
# å¤åˆ¶ä¿®æ”¹å¥½çš„è½¬æ¢è„šæœ¬
cp /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/utils/export_yoloV8.py \
   /opt/nvidia/deepstream/deepstream/my_apps/ultralytics/
```

**è„šæœ¬æ”¹è¿›è¯´æ˜**ï¼š
æˆ‘ä»¬çš„è½¬æ¢è„šæœ¬å·²è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
1. âœ… PyTorch 2.6+ `weights_only` å‚æ•°é—®é¢˜
2. âœ… TorchDynamo å¯¼å‡ºå…¼å®¹æ€§é—®é¢˜
3. âœ… ONNX ä¼˜åŒ–å’Œç®€åŒ–

---

### æ­¥éª¤ 4ï¼šè½¬æ¢æ¨¡å‹ä¸º ONNX

#### 4.1 åŸºç¡€è½¬æ¢ï¼ˆé»˜è®¤ 640Ã—640ï¼‰

```bash
cd /opt/nvidia/deepstream/deepstream/my_apps/ultralytics

python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    --dynamic
```

#### 4.2 è‡ªå®šä¹‰è¾“å…¥å°ºå¯¸

```bash
# æ–¹å¼ 1ï¼šæ­£æ–¹å½¢è¾“å…¥ï¼ˆ1280Ã—1280ï¼‰
python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    -s 1280 \
    --dynamic

# æ–¹å¼ 2ï¼šçŸ©å½¢è¾“å…¥ï¼ˆ1920Ã—1080ï¼‰
python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    -s 1920 1080 \
    --dynamic
```

#### 4.3 å…¶ä»–å¸¸ç”¨å‚æ•°

```bash
# ç®€åŒ– ONNX æ¨¡å‹ï¼ˆDeepStream >= 6.0ï¼‰
python3 export_yoloV8.py -w model.pt --dynamic --simplify

# é™æ€ batch sizeï¼ˆä¾‹å¦‚ batch=4ï¼‰
python3 export_yoloV8.py -w model.pt --batch 4

# æŒ‡å®š opset ç‰ˆæœ¬ï¼ˆDeepStream 5.1 ä½¿ç”¨ opset 12ï¼‰
python3 export_yoloV8.py -w model.pt --dynamic --opset 12
```

**å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `-w, --weights` | æ¨¡å‹æƒé‡è·¯å¾„ | `-w yolov8n.pt` |
| `-s, --size` | è¾“å…¥å°ºå¯¸ | `-s 640` æˆ– `-s 1920 1080` |
| `--dynamic` | åŠ¨æ€ batch size | `--dynamic` |
| `--batch` | é™æ€ batch size | `--batch 4` |
| `--simplify` | ç®€åŒ– ONNX æ¨¡å‹ | `--simplify` |
| `--opset` | ONNX opset ç‰ˆæœ¬ | `--opset 12` |

---

### æ­¥éª¤ 5ï¼šç»„ç»‡æ¨¡å‹æ–‡ä»¶

å°†å¯¼å‡ºçš„ ONNX æ¨¡å‹å’Œæ ‡ç­¾æ–‡ä»¶ç§»åŠ¨åˆ° models ç›®å½•ï¼š

```bash
# å¯¼å‡ºçš„ ONNX æ¨¡å‹é»˜è®¤åç§°ä¸º yolov8.onnx
# ç§»åŠ¨åˆ° models ç›®å½•ï¼ˆæ ¹æ®ä½ çš„æ¨¡å‹ç±»å‹å‘½åï¼‰
mv yolov8.onnx \
   /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/your_model_name.onnx

# å¦‚æœæœ‰æ ‡ç­¾æ–‡ä»¶ï¼Œä¹Ÿä¸€èµ·ç§»åŠ¨
mv labels.txt \
   /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/your_labels.txt

# æŸ¥çœ‹ models ç›®å½•å†…å®¹
ls -lh /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/
```

**models ç›®å½•ç»“æ„ç¤ºä¾‹**ï¼š
```
models/
â”œâ”€â”€ yolov8n_person.onnx       # äººå‘˜æ£€æµ‹æ¨¡å‹
â”œâ”€â”€ yolov8n_vehicle.onnx      # è½¦è¾†æ£€æµ‹æ¨¡å‹
â”œâ”€â”€ yolov8s_highway.onnx      # é«˜é€Ÿå…¬è·¯åœºæ™¯æ¨¡å‹
â”œâ”€â”€ labels_coco.txt           # COCO æ•°æ®é›†æ ‡ç­¾
â”œâ”€â”€ labels_custom.txt         # è‡ªå®šä¹‰æ ‡ç­¾
â””â”€â”€ ...                       # å…¶ä»–æ¨¡å‹æ–‡ä»¶
```

---

### æ­¥éª¤ 6ï¼šä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘é…ç½®æ–‡ä»¶ï¼š
```bash
cd /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/examples/02_custom_model_video_detection
nano dstest1_pgie_config.txt
```

**å…³é”®é…ç½®é¡¹ï¼ˆéœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†ï¼‰**ï¼š

```ini
[property]
gpu-id=0
net-scale-factor=0.0039215697906911373

# 1. ä¿®æ”¹ä¸ºä½ çš„ ONNX æ¨¡å‹è·¯å¾„ï¼ˆç›¸å¯¹è·¯å¾„æˆ–ç»å¯¹è·¯å¾„ï¼‰
model-file=../../models/your_model_name.onnx

# 2. ä¿®æ”¹ä¸ºä½ çš„æ ‡ç­¾æ–‡ä»¶è·¯å¾„
labelfile-path=../../models/your_labels.txt

# 3. ä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹ç±»åˆ«æ•°é‡
num-detected-classes=80  # ä¾‹å¦‚ COCO æ•°æ®é›†æ˜¯ 80 ç±»

# 4. ä¿®æ”¹è¾“å…¥å°ºå¯¸ï¼ˆéœ€ä¸å¯¼å‡ºæ—¶çš„å°ºå¯¸ä¸€è‡´ï¼‰
infer-dims=3;640;640  # æ ¼å¼ï¼šchannels;height;width
# å¦‚æœå¯¼å‡ºæ—¶ä½¿ç”¨ -s 1280ï¼Œè¿™é‡Œæ”¹ä¸º 3;1280;1280

# TensorRT å¼•æ“æ–‡ä»¶ï¼ˆé¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ç”Ÿæˆï¼‰
model-engine-file=../../models/your_model_b1_gpu0_fp16.engine

# æ¨ç†ç²¾åº¦ï¼ˆ2=FP16ï¼Œé€Ÿåº¦æ›´å¿«ï¼Œæ¨èï¼‰
network-mode=2

batch-size=1
interval=0
gie-unique-id=1

# è‡ªå®šä¹‰åº“è·¯å¾„ï¼ˆDeepStream-Yolo çš„è§£æåº“ï¼‰
custom-lib-path=/opt/nvidia/deepstream/deepstream/my_apps/DeepStream-Yolo/nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
parse-bbox-func-name=NvDsInferParseYolo

# åå¤„ç†å‚æ•°
cluster-mode=2
nms-iou-threshold=0.45
pre-cluster-threshold=0.25

maintain-aspect-ratio=1
symmetric-padding=1
```

**é…ç½®å‚æ•°è¯´æ˜**ï¼š

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹å€¼ | æ³¨æ„äº‹é¡¹ |
|------|------|--------|---------|
| `model-file` | ONNX æ¨¡å‹è·¯å¾„ | `../../models/yolov8n.onnx` | å¿…é¡»ä¸å®é™…æ–‡ä»¶è·¯å¾„ä¸€è‡´ |
| `labelfile-path` | æ ‡ç­¾æ–‡ä»¶è·¯å¾„ | `../../models/labels.txt` | æ¯è¡Œä¸€ä¸ªç±»åˆ«åç§° |
| `num-detected-classes` | ç±»åˆ«æ•°é‡ | `80` | å¿…é¡»ä¸æ¨¡å‹è®­ç»ƒæ—¶çš„ç±»åˆ«æ•°ä¸€è‡´ |
| `infer-dims` | è¾“å…¥å°ºå¯¸ | `3;640;640` | å¿…é¡»ä¸ ONNX å¯¼å‡ºæ—¶ä¸€è‡´ |
| `network-mode` | æ¨ç†ç²¾åº¦ | `0`=FP32, `2`=FP16 | FP16 æ¨èï¼ˆé€Ÿåº¦å¿«ï¼Œç²¾åº¦æŸå¤±å°ï¼‰ |
| `pre-cluster-threshold` | ç½®ä¿¡åº¦é˜ˆå€¼ | `0.25` | é™ä½å¯æ£€æµ‹æ›´å¤šç›®æ ‡ï¼Œä½†è¯¯æ£€å¢åŠ  |
| `nms-iou-threshold` | NMS IOU é˜ˆå€¼ | `0.45` | æ§åˆ¶é‡å æ¡†çš„è¿‡æ»¤ç¨‹åº¦ |

---

### æ­¥éª¤ 7ï¼šè¿è¡Œæ£€æµ‹

```bash
cd /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/examples/02_custom_model_video_detection

# è¿è¡Œç¤ºä¾‹
python3 01_custom_model_video_detection.py \
    /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.h264
```

**é¢„æœŸè¾“å‡º**ï¼š

```
=======================================================
Using config file: dstest1_pgie_config.txt
=======================================================

0:00:00.523410234 12345 0x7f8b4c000b20 INFO nvinfer gstnvinfer_impl.cpp:343:
Loading ONNX model: ../../models/yolov8n.onnx
Building TensorRT engine...
[TensorRT] This may take a few minutes...

Frame Number=0 Number of Objects=12 person=3 car=7 truck=2
Frame Number=100 Number of Objects=15 person=4 car=9 truck=2
Frame Number=200 Number of Objects=18 person=5 car=11 truck=2
...

Average FPS: 487.3
Total processing time: 3.12s
Video saved to: output/custom_detection_output.mp4
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1ï¼šæ¨¡å‹åŠ è½½å¤±è´¥ - `weights_only` é”™è¯¯

**å®Œæ•´é”™è¯¯ä¿¡æ¯**ï¼š
```python
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, 
to do so you have two options, do those steps only if you trust the source of the checkpoint.
(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument 
in `torch.load` from `False` to `True`.
```

**åŸå› **ï¼šPyTorch 2.6+ é»˜è®¤å¯ç”¨äº†å®‰å…¨åŠ è½½æ¨¡å¼

**è§£å†³æ–¹æ¡ˆ**ï¼š

ä¿®æ”¹ `export_yoloV8.py` ç¬¬ 38 è¡Œï¼š

```python
# ä¿®æ”¹å‰
ckpt = torch.load(weights, map_location='cpu')

# ä¿®æ”¹å
ckpt = torch.load(weights, map_location='cpu', weights_only=False)
```

---

### é—®é¢˜ 2ï¼šTorchDynamo å¯¼å‡ºé”™è¯¯

**å®Œæ•´é”™è¯¯ä¿¡æ¯**ï¼š
```python
AttributeError: 'float' object has no attribute 'node'
While executing %item : [num_users=1] = call_function[target=torch.ops.aten.item.default]
```

**åŸå› **ï¼šTorchDynamo ä¸ YOLOv8 çš„æŸäº›æ“ä½œä¸å…¼å®¹

**è§£å†³æ–¹æ¡ˆ**ï¼š

ä¿®æ”¹ `export_yoloV8.py` çš„ `torch.onnx.export()` è°ƒç”¨ï¼š

```python
torch.onnx.export(
    model, onnx_input_im, onnx_output_file,
    verbose=False, 
    opset_version=args.opset,
    do_constant_folding=True,
    input_names=['input'], 
    output_names=['output'],
    dynamic_axes=dynamic_axes if args.dynamic else None,
    dynamo=False  # æ·»åŠ è¿™ä¸€è¡Œ
)
```

---

### é—®é¢˜ 3ï¼šTensorRT å¼•æ“æ„å»ºå¤±è´¥

**ç—‡çŠ¶**ï¼šé¦–æ¬¡è¿è¡Œæ—¶å¡åœ¨ "Building TensorRT engine..."

**åŸå› **ï¼šTensorRT æ­£åœ¨ä¼˜åŒ–æ¨¡å‹ï¼Œè¿™æ˜¯æ­£å¸¸ç°è±¡

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **è€å¿ƒç­‰å¾…**ï¼šé¦–æ¬¡æ„å»ºå¯èƒ½éœ€è¦ 2-10 åˆ†é’Ÿï¼Œå–å†³äºæ¨¡å‹å¤§å°å’Œ GPU
2. **æŸ¥çœ‹è¿›åº¦**ï¼š
   ```bash
   # æŸ¥çœ‹ GPU ä½¿ç”¨æƒ…å†µ
   watch -n 1 nvidia-smi
   ```
3. **é‡ç”¨å¼•æ“**ï¼šå¼•æ“æ–‡ä»¶ä¼šä¿å­˜åœ¨é…ç½®ä¸­æŒ‡å®šçš„è·¯å¾„ï¼Œåç»­è¿è¡Œä¼šç›´æ¥åŠ è½½

**åŠ é€ŸæŠ€å·§**ï¼š
```ini
# åœ¨é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šå›ºå®šçš„å¼•æ“æ–‡ä»¶è·¯å¾„
model-engine-file=../../models/yolov8n_custom/model_b1_gpu0_fp16.engine

# ä½¿ç”¨ FP16 ç²¾åº¦ï¼ˆæ›´å¿«ï¼Œç²¾åº¦æŸå¤±å¾ˆå°ï¼‰
network-mode=2
```

---

### é—®é¢˜ 4ï¼šæ£€æµ‹ç»“æœä¸ºç©ºæˆ–å¼‚å¸¸

**å¯èƒ½åŸå› å’Œè§£å†³æ–¹æ¡ˆ**ï¼š

#### åŸå›  1ï¼šç½®ä¿¡åº¦é˜ˆå€¼è¿‡é«˜
```ini
# é™ä½é˜ˆå€¼
pre-cluster-threshold=0.1  # ä» 0.25 é™ä½åˆ° 0.1
```

#### åŸå›  2ï¼šè¾“å…¥å°ºå¯¸ä¸åŒ¹é…
```ini
# åœ¨ dstest1_pgie_config.txt ä¸­ç¡®ä¿ä¸å¯¼å‡ºæ—¶ä¸€è‡´
infer-dims=3;640;640  # éœ€è¦ä¸ export_yoloV8.py ä¸­çš„ -s å‚æ•°ä¸€è‡´
```

#### åŸå›  3ï¼šæ ‡ç­¾æ–‡ä»¶é”™è¯¯
```bash
# æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼Œä¸è¦æœ‰ç©ºè¡Œï¼‰
cat /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/your_labels.txt

# æ ‡ç­¾æ–‡ä»¶ç¤ºä¾‹ï¼ˆæ­£ç¡®æ ¼å¼ï¼‰
person
bicycle
car
motorcycle
# ... æ¯è¡Œä¸€ä¸ªç±»åˆ«ï¼Œæ— é¢å¤–ç©ºè¡Œ
```

#### åŸå›  4ï¼šNMS å‚æ•°ä¸å½“
```ini
# åœ¨ dstest1_pgie_config.txt ä¸­è°ƒæ•´ NMS å‚æ•°
nms-iou-threshold=0.45
cluster-mode=2  # 2=DBSCAN, 3=NMS
```

---

### é—®é¢˜ 5ï¼šå†…å­˜ä¸è¶³ (OOM)

**ç—‡çŠ¶**ï¼š`CUDA out of memory` é”™è¯¯

**è§£å†³æ–¹æ¡ˆ**ï¼š

```ini
# æ–¹æ³• 1ï¼šé™ä½ batch size
batch-size=1

# æ–¹æ³• 2ï¼šä½¿ç”¨æ›´å°çš„è¾“å…¥å°ºå¯¸
infer-dims=3;416;416  # ä» 640 é™ä½åˆ° 416

# æ–¹æ³• 3ï¼šä½¿ç”¨ INT8 ç²¾åº¦
network-mode=1
```

---

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç²¾åº¦ vs é€Ÿåº¦æƒè¡¡

| ç²¾åº¦æ¨¡å¼ | é€Ÿåº¦ | ç²¾åº¦æŸå¤± | æ¨èåœºæ™¯ |
|---------|------|---------|---------|
| FP32 | åŸºå‡† | 0% | å¼€å‘è°ƒè¯• |
| FP16 | 1.5-2Ã— | <1% | ç”Ÿäº§ç¯å¢ƒï¼ˆæ¨èï¼‰ |
| INT8 | 2-3Ã— | 1-3% | å®æ—¶å¤„ç† |

**é…ç½®ç¤ºä¾‹**ï¼š
```ini
# åœ¨ dstest1_pgie_config.txt ä¸­è®¾ç½®
# FP16 æ¨¡å¼ï¼ˆæ¨èï¼‰
network-mode=2
```

### 2. è¾“å…¥å°ºå¯¸ä¼˜åŒ–

| è¾“å…¥å°ºå¯¸ | é€Ÿåº¦ | ç²¾åº¦ | æ¨èåœºæ™¯ |
|---------|------|------|---------|
| 320Ã—320 | æœ€å¿« | ä½ | å®æ—¶ä½åˆ†è¾¨ç‡ |
| 416Ã—416 | å¿« | ä¸­ | ä¸€èˆ¬åœºæ™¯ |
| 640Ã—640 | ä¸­ | é«˜ | æ ‡å‡†åœºæ™¯ï¼ˆæ¨èï¼‰ |
| 1280Ã—1280 | æ…¢ | æœ€é«˜ | é«˜ç²¾åº¦éœ€æ±‚ |

### 3. Batch Size è°ƒæ•´

```bash
# æµ‹è¯•ä¸åŒ batch size çš„æ€§èƒ½
# ç¼–è¾‘ dstest1_pgie_config.txtï¼Œä¿®æ”¹ batch-size å‚æ•°
for bs in 1 2 4 8; do
    echo "Testing batch_size=$bs"
    sed -i "s/batch-size=.*/batch-size=$bs/" dstest1_pgie_config.txt
    python3 01_custom_model_video_detection.py test_video.mp4
done
```

**å»ºè®®**ï¼š
- å•æµæ¨ç†ï¼š`batch-size=1`
- å¤šæµæ¨ç†ï¼š`batch-size=4` æˆ– `batch-size=8`

### 4. å¤šæµå¤„ç†

```python
# ç¤ºä¾‹ï¼šå¤„ç† 4 è·¯è§†é¢‘æµ
streams = [
    "rtsp://camera1/stream",
    "rtsp://camera2/stream",
    "rtsp://camera3/stream",
    "rtsp://camera4/stream"
]

# é…ç½® streammux
streammux.set_property("batch-size", len(streams))
```

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ
- GPU: NVIDIA RTX 3080
- è§†é¢‘: 3840Ã—2160, 12179 å¸§
- DeepStream: 8.0
- TensorRT: 8.6

### æµ‹è¯•ç»“æœ

| æ¨¡å‹ | è¾“å…¥å°ºå¯¸ | Batch Size | ç²¾åº¦ | å¹³å‡ FPS | æ€»è€—æ—¶ |
|------|---------|-----------|------|---------|--------|
| YOLOv8n | 640Ã—640 | 1 | FP32 | 497.21 | 24.49s |
| YOLOv8n | 640Ã—640 | 1 | FP16 | 623.45 | 19.54s |
| YOLOv8s | 640Ã—640 | 1 | FP16 | 412.33 | 29.54s |
| YOLOv8m | 640Ã—640 | 1 | FP16 | 287.56 | 42.35s |
| YOLOv8n | 1280Ã—1280 | 1 | FP16 | 185.32 | 65.73s |
| Custom Model | 1920Ã—1920 | 1 | FP16 | 310.34 | 39.25s |

---

## ğŸ“ å®Œæ•´æ–‡ä»¶ç»“æ„

```
Deepstream_Python_Stack/
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ 02_custom_model_video_detection/
â”‚       â”œâ”€â”€ README.md                              # æœ¬æ–‡æ¡£
â”‚       â”œâ”€â”€ dstest1_pgie_config.txt               # æ¨¡å‹é…ç½®æ–‡ä»¶ â­
â”‚       â”œâ”€â”€ 01_custom_model_video_detection.py    # å•è§†é¢‘æ£€æµ‹è„šæœ¬
â”‚       â”œâ”€â”€ 02_custom_model_rtsp_output.py        # RTSP è¾“å‡ºè„šæœ¬
â”‚       â””â”€â”€ output/                               # è¾“å‡ºç›®å½•
â”‚           â””â”€â”€ custom_detection_output.mp4
â””â”€â”€ models/                                        # æ¨¡å‹å­˜å‚¨ç›®å½• â­
    â”œâ”€â”€ yolov8n.onnx                              # YOLOv8n æ¨¡å‹
    â”œâ”€â”€ yolov8n_person.onnx                       # äººå‘˜æ£€æµ‹æ¨¡å‹
    â”œâ”€â”€ yolov8s_vehicle.onnx                      # è½¦è¾†æ£€æµ‹æ¨¡å‹
    â”œâ”€â”€ labels_coco.txt                           # COCO æ ‡ç­¾æ–‡ä»¶
    â”œâ”€â”€ labels_custom.txt                         # è‡ªå®šä¹‰æ ‡ç­¾æ–‡ä»¶
    â””â”€â”€ model_b1_gpu0_fp16.engine                 # TensorRT å¼•æ“æ–‡ä»¶ï¼ˆè‡ªåŠ¨ç”Ÿæˆï¼‰
```

**ç›®å½•è¯´æ˜**ï¼š
- `examples/02_custom_model_video_detection/` - ç¤ºä¾‹ä»£ç å’Œé…ç½®æ–‡ä»¶
- `models/` - æ‰€æœ‰æ¨¡å‹ç›¸å…³æ–‡ä»¶çš„ç»Ÿä¸€å­˜å‚¨ä½ç½®
- `dstest1_pgie_config.txt` - æ ¸å¿ƒé…ç½®æ–‡ä»¶ï¼Œéœ€è¦æ ¹æ®å®é™…æ¨¡å‹è·¯å¾„ä¿®æ”¹

---

## ğŸ”— ç›¸å…³èµ„æº

### å®˜æ–¹æ–‡æ¡£
- [DeepStream-Yolo GitHub](https://github.com/marcoslucianops/DeepStream-Yolo)
- [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics)
- [TensorRT Documentation](https://docs.nvidia.com/deeplearning/tensorrt/)

### æ¨¡å‹ä¸‹è½½
- [YOLOv8 é¢„è®­ç»ƒæ¨¡å‹](https://github.com/ultralytics/assets/releases)
- [COCO æ•°æ®é›†](https://cocodataset.org/)

### è¿›é˜¶æ•™ç¨‹
- [è‡ªå®šä¹‰æ•°æ®é›†è®­ç»ƒ](https://docs.ultralytics.com/modes/train/)
- [æ¨¡å‹å¯¼å‡ºè¯¦è§£](https://docs.ultralytics.com/modes/export/)
- [TensorRT ä¼˜åŒ–æŒ‡å—](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/)

---

## ğŸ¤ è´¡çŒ®

å¦‚æœä½ é‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œæ¬¢è¿ï¼š
1. æäº¤ Issue
2. æäº¤ Pull Request
3. åœ¨è®¨è®ºåŒºåˆ†äº«ç»éªŒ

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT License å¼€æºåè®®

---

<div align="center">

**ä¸‹ä¸€æ­¥**ï¼šå°è¯• [å¤šç›®æ ‡è·Ÿè¸ª](../03_object_tracking/README.md) æˆ– [RTSP æµè¾“å‡º](../04_rtsp_single_stream/README.md)

</div>

---

## English Version

### ğŸ“– Overview

This example demonstrates how to use custom YOLOv8 models for video object detection in DeepStream, including complete model conversion, configuration, and inference workflow.

### âœ¨ Features

- âœ… Support for YOLOv8 series models (n/s/m/l/x)
- âœ… Custom input sizes (default 640Ã—640, adjustable)
- âœ… Dynamic batch size support
- âœ… ONNX model conversion and optimization
- âœ… TensorRT accelerated inference
- âœ… Performance monitoring and FPS statistics

### ğŸ“‹ Prerequisites

Ensure you have completed the basic environment setup:

```bash
# 1. DeepStream 8.0 environment installed
deepstream-app --version

# 2. Python Bindings (pyds) installed
python3 -c "import pyds; print(pyds.__version__)"

# 3. DeepStream-Yolo compiled
ls /opt/nvidia/deepstream/deepstream/my_apps/DeepStream-Yolo/nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
```

If not completed, refer to the main README's [Complete Deployment Process](../../README_EN.md#complete-deployment-process).

---

## ğŸš€ Quick Start

### Step 1: Install DeepStream-Yolo

If you haven't installed DeepStream-Yolo yet:

```bash
# Navigate to working directory
cd /opt/nvidia/deepstream/deepstream/my_apps

# Clone DeepStream-Yolo repository
git clone https://github.com/marcoslucianops/DeepStream-Yolo.git
cd DeepStream-Yolo

# Set CUDA version (according to DeepStream version)
export CUDA_VER=12.8  # DeepStream 8.0

# Compile custom library
make -C nvdsinfer_custom_impl_Yolo clean && \
make -C nvdsinfer_custom_impl_Yolo

# Verify compilation
ls -lh nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
```

**CUDA Version Reference**:

| DeepStream Version | CUDA Version |
|-------------------|--------------|
| 8.0 | 12.8 |
| 7.1 | 12.6 |
| 7.0 / 6.4 | 12.2 |
| 6.3 | 12.1 |
| 6.2 | 11.8 |

---

### Step 2: Setup YOLOv8 Environment

```bash
# Clone ultralytics repository
cd /opt/nvidia/deepstream/deepstream/my_apps
git clone https://github.com/ultralytics/ultralytics.git
cd ultralytics

# Install dependencies
pip3 install -e .
pip3 install onnx onnxslim onnxruntime tensorrt
```

---

### Step 3: Copy Model Conversion Script

```bash
# Copy the modified conversion script
cp /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/utils/export_yoloV8.py \
   /opt/nvidia/deepstream/deepstream/my_apps/ultralytics/
```

**Script Improvements**:
Our conversion script has resolved:
1. âœ… PyTorch 2.6+ `weights_only` parameter issue
2. âœ… TorchDynamo export compatibility issue
3. âœ… ONNX optimization and simplification

---

### Step 4: Convert Model to ONNX

#### 4.1 Basic Conversion (default 640Ã—640)

```bash
cd /opt/nvidia/deepstream/deepstream/my_apps/ultralytics

python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    --dynamic
```

#### 4.2 Custom Input Size

```bash
# Method 1: Square input (1280Ã—1280)
python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    -s 1280 \
    --dynamic

# Method 2: Rectangle input (1920Ã—1080)
python3 export_yoloV8.py \
    -w /path/to/your/yolov8n.pt \
    -s 1920 1080 \
    --dynamic
```

---

### Step 5: Organize Model Files

```bash
# Create model directory
MODEL_NAME="yolov8n_custom"
mkdir -p /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/$MODEL_NAME

# Move ONNX model
mv yolov8.onnx \
   /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/$MODEL_NAME/

# Create labels file
cat > /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/models/$MODEL_NAME/labels.txt << EOF
person
car
truck
bus
EOF
```

---

### Step 6: Configure Model Parameters

Edit configuration file `configs/models/custom_yolov8_config.txt`:

```ini
[property]
gpu-id=0
net-scale-factor=0.0039215697906911373
model-file=../../models/yolov8n_custom/yolov8.onnx
labelfile-path=../../models/yolov8n_custom/labels.txt
num-detected-classes=4
infer-dims=3;640;640

# TensorRT engine configuration
model-engine-file=../../models/yolov8n_custom/model_b1_gpu0_fp16.engine
batch-size=1
network-mode=2  # 0=FP32, 2=FP16
interval=0
gie-unique-id=1

# Custom library path
custom-lib-path=/opt/nvidia/deepstream/deepstream/my_apps/DeepStream-Yolo/nvdsinfer_custom_impl_Yolo/libnvdsinfer_custom_impl_Yolo.so
parse-bbox-func-name=NvDsInferParseYolo

# Post-processing parameters
cluster-mode=2
nms-iou-threshold=0.45
pre-cluster-threshold=0.25
```

---

### Step 7: Run Detection

```bash
cd /opt/nvidia/deepstream/deepstream/my_apps/Deepstream_Python_Stack/examples/02_custom_model

python3 01_custom_model_video_detection.py \
    /opt/nvidia/deepstream/deepstream/samples/streams/sample_720p.h264
```

---

## ğŸ› Troubleshooting

### Issue 1: Model Loading Failed - `weights_only` Error

**Solution**: Modify line 38 in `export_yoloV8.py`:

```python
ckpt = torch.load(weights, map_location='cpu', weights_only=False)
```

---

### Issue 2: TorchDynamo Export Error

**Solution**: Add `dynamo=False` to `torch.onnx.export()`:

```python
torch.onnx.export(
    model, onnx_input_im, onnx_output_file,
    ...,
    dynamo=False
)
```

---

## ğŸ“Š Performance Benchmarks

### Test Environment
- GPU: NVIDIA RTX 3080
- Video: 3840Ã—2160, 12179 frames
- DeepStream: 8.0

### Results

| Model | Input Size | Precision | Avg FPS | Total Time |
|-------|-----------|-----------|---------|------------|
| YOLOv8n | 640Ã—640 | FP16 | 623.45 | 19.54s |
| YOLOv8s | 640Ã—640 | FP16 | 412.33 | 29.54s |
| YOLOv8m | 640Ã—640 | FP16 | 287.56 | 42.35s |

---

<div align="center">

**Next Steps**: Try [Object Tracking](../03_object_tracking/README.md) or [RTSP Streaming](../04_rtsp_single_stream/README.md)

</div>